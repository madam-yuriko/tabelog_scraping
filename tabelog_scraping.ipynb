{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import const\n",
    "import datetime\n",
    "import re\n",
    "import sys\n",
    "import jaconv\n",
    "\n",
    "\n",
    "name = '渋谷ヒカリエ'\n",
    "df_input = pd.read_csv(f'input/{name}.csv', header=0)\n",
    "\n",
    "df_blank = pd.DataFrame(columns=const.SELECTOR_DIC.keys())\n",
    "df_blank = df_blank.set_index('ID')\n",
    "dt_now = '{0:%Y%m%d}'.format(datetime.datetime.now())\n",
    "# for i in df_input.itertuples():\n",
    "\n",
    "# 途中スタート位置\n",
    "before_df = pd.read_csv('data_base_all.csv', index_col='URL', encoding='utf-8', low_memory=False)\n",
    "before_t_id = '00000000' if len(before_df) == 0 else str(before_df.iloc[-1]['ID']).zfill(8)\n",
    "skip = [int(before_t_id[0:2]), int(before_t_id[-6:])]\n",
    "\n",
    "for i in range(1, 48):\n",
    "    # 県ごと\n",
    "    failed_cnt = 0\n",
    "    for j in range(1000000):\n",
    "        t_id = str(i*1000000+j).zfill(8)\n",
    "        if failed_cnt >= 100:\n",
    "            break\n",
    "        if (i <= skip[0] - 1) or (i == skip[0] and j <= skip[1]):\n",
    "            continue\n",
    "        df = df_blank.copy()\n",
    "    #     url = i[2]\n",
    "        url = f'https://tabelog.com/hokkaido/A0101/A010101/{t_id}/'\n",
    "        shop_data = []\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            failed_cnt = 0\n",
    "            print(f'load:{url} success!:{response.status_code}')\n",
    "        else:\n",
    "            print(f'load:{url} failed:{response.status_code}')\n",
    "            failed_cnt += 1\n",
    "            continue\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        for key, selector in const.SELECTOR_DIC.items():\n",
    "            elems_address = soup.find_all('p', class_='rstinfo-table__address')\n",
    "            elems_price = soup.find_all('span', class_='rdheader-budget__price')\n",
    "            elems_price_r = soup.find_all('em', class_='gly-b-dinner')\n",
    "            elems_award = soup.find_all('div', class_='rstinfo-table-badge-award')\n",
    "            if key in ['説明', '説明詳細']:\n",
    "                elsms_attr = soup.find_all(selector[0], class_=selector[1])\n",
    "            if key == 'ID':\n",
    "                continue\n",
    "            try:\n",
    "                value = None\n",
    "                if key in 'URL':\n",
    "                    value = url\n",
    "                elif key in ['取得日時']:\n",
    "                    value = dt_now\n",
    "                elif key in ['都道府県', '所在地', '施設名']:\n",
    "                    value = elems_address[0].contents[selector].get_text()\n",
    "                elif key in ['説明']:\n",
    "                    value = elsms_attr[0].contents[0]\n",
    "                elif key in ['説明詳細']:\n",
    "                    value = elsms_attr[0].get_text()\n",
    "                elif key in ['予算(夜)', '予算(昼)']:\n",
    "                    value = elems_price[selector].get_text()\n",
    "                elif key in ['ステータス']:\n",
    "                    for selec in selector:\n",
    "                        elems = soup.select(selec)\n",
    "                        if len(elems) >= 1:\n",
    "                            value = elems[0].contents[0]\n",
    "                elif key in ['食べログアワード']:\n",
    "                    value = ''\n",
    "                    for elem in elems_award:\n",
    "                        text = elem.contents[1].get_text()\n",
    "                        if '受賞店' in text:\n",
    "                            value += text.strip().replace('年', ' ').replace('受賞店', '') + '/'\n",
    "                elif key in ['百名店']:\n",
    "                    value = ''\n",
    "                    for elem in elems_award:\n",
    "                        text = elem.contents[1].get_text()\n",
    "                        if '選出店' in text:\n",
    "                            value += text.strip().replace('百名店', '').replace('選出店', '').replace(' ', '') + '/'\n",
    "                elif key in ['席数']:\n",
    "                    elems = soup.find_all(selector[0], class_=selector[1])\n",
    "                    value = elems[1].find_all('p')[0].get_text()\n",
    "                    value = value if re.search(r'席$', value) else ''\n",
    "                elif key in ['ホームページ']:\n",
    "                    elems = soup.find_all('a', rel='nofollow noopener')\n",
    "                    value = elems[0].attrs['href']\n",
    "                elif key in ['公式アカウント']:\n",
    "                    elems = soup.find_all('a', rel='nofollow noopener')\n",
    "                    value = elems[1].attrs['href']\n",
    "                elif key in ['最寄り駅', '点数', 'オープン日']:\n",
    "                    elems = soup.find_all(selector[0], class_=selector[1])\n",
    "                    value = elems[0].get_text()\n",
    "                elif key in ['口コミ数', '保存件数']:\n",
    "                    elems = soup.find_all(selector[0], class_=selector[1])\n",
    "                    value = elems[0].find_all('em', class_='num')[0].get_text()\n",
    "                    value = '0' if value == ' - ' else value\n",
    "                else:\n",
    "                    elems = soup.select(selector)\n",
    "                    value = elems[0].contents[0]\n",
    "                value = jaconv.z2h(value, kana=False, digit=True, ascii=True).replace('~', '～').replace(',', '').replace('\\n', '').strip()\n",
    "                df.loc[t_id, key] = value\n",
    "            except Exception:\n",
    "#                 print(key, sys.exc_info())\n",
    "                continue\n",
    "        df.to_csv(f'data_base_all.csv', mode='a', header=None)\n",
    "    # df = df.sort_values(['点数', '口コミ数', '保存件数'], ascending=False)\n",
    "    # df.to_csv(f'data_base_all.csv', mode='a', header=None)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "todofuken = '岩手'\n",
    "institution = ''\n",
    "genre = ''\n",
    "\n",
    "print('load csv')\n",
    "before_df = pd.read_csv('data_base_all.csv', index_col='URL', encoding='utf-8', low_memory=False)\n",
    "# before_t_id = '00000000' if len(before_df) == 1 else str(before_df.iloc[-1]['ID']).zfill(8)\n",
    "\n",
    "# print('load completed')\n",
    "# df = df[df.都道府県.str.contains(todofuken) & (df.ジャンル1.str.contains(genre) | df.ジャンル2.str.contains(genre) | df.ジャンル3.str.contains(genre))]\n",
    "# df = df.sort_values(['点数', '口コミ数', '保存件数'], ascending=False)\n",
    "# df.to_csv('result.csv', encoding='utf-8')\n",
    "\n",
    "# print(f'HIT件数：{len(df)} 件')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_df[before_df.都道府県.str.contains('北海道|青森')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_base_all.csv', encoding='utf-8')\n",
    "df = df.sort_values(['点数', '口コミ数', '保存件数'], ascending=False)\n",
    "df = df.iloc[0:10][['店名', '点数', '口コミ数', '保存件数', 'ジャンル1']]\n",
    "\n",
    "for i in df.itertuples():\n",
    "    print(i[1:6])\n",
    "    \n",
    "    \n",
    "aaa = [1, 2, 3]\n",
    "aaa.remove(2)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [11, None, 15, 4, 5],\n",
    "        [2, 12, 10, 8, 16],\n",
    "        [17, 24, 14, 13, 23],\n",
    "        [19, 6, 18, None, 7],\n",
    "        [3, 9, 20, 21, 1],\n",
    "    ],\n",
    "    index=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    columns=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    ")\n",
    "# df = df.style.highlight_null(\"red\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "response = requests.get('https://tabelog.com/hokkaido/A0101/A010101/12000509/')\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# elems = soup.select('#rst-data-head > table:nth-child(2) > tbody > tr:nth-child(6) > td > p > span:nth-child(2) > a:nth-child(1)')\n",
    "# print(elems)\n",
    "# elems = soup.select('#rst-data-head > table:nth-child(2) > tbody > tr:nth-child(6) > td > p > span:nth-child(2) > a:nth-child(2)')\n",
    "# print(elems)\n",
    "# elems = soup.select('#rst-data-head > table:nth-child(2) > tbody > tr:nth-child(6) > td > p > span:nth-child(3)')\n",
    "# print(elems)\n",
    "\n",
    "\n",
    "# elems = soup.select('#rst-data-head > table:nth-child(2) > tbody > tr:nth-child(3) > td > p > span:nth-child(2) > a:nth-child(1)')\n",
    "# print(elems)\n",
    "# elems = soup.select('#rst-data-head > table:nth-child(2) > tbody > tr:nth-child(3) > td > p > span:nth-child(2) > a:nth-child(2)')\n",
    "# print(elems)\n",
    "# elems = soup.select('#rst-data-head > table:nth-child(4) > tbody > tr:nth-child(1) > td > p')\n",
    "# print(elems[0].contents[0])\n",
    "\n",
    "elems = soup.find_all('span', class_='rdheader-rating__review-target')\n",
    "value = elems[0].find_all('em', class_='num')[0].get_text()\n",
    "value = 0 if value == ' - ' else value\n",
    "value = jaconv.z2h(value, kana=False, digit=True, ascii=True).replace('~', '～').replace(',', '').replace('\\n', '').strip()\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv('input/input.csv', header=0)\n",
    "for i in df_input.itertuples():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaconv\n",
    "\n",
    "jaconv.z2h('克美ビル　４Ｆ', kana=False, digit=True, ascii=True)\n",
    "\n",
    "value = '4'\n",
    "value = 0 if value == '-' else 0 if value == '' else value\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "df = pd.DataFrame({'a': ['aaa', 'bbb', 'ccc'], 'b': [4, 5, 6]})\n",
    "df[df.a.str.contains('aa|bb')]\n",
    "df.a.replace('a', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "aaa = '2021 Gold/2020 Silver/2019 Gold/2018 Bronze/2017 Gold/'\n",
    "ret_str = ''\n",
    "for i in aaa.split('/'):\n",
    "    ret_str += i[2:6].replace(' ', '') + '/'\n",
    "ret_str[0:-2]\n",
    "\n",
    "bbb = 'ラーメン2020/ラーメン2019/ラーメン2018/'\n",
    "ret_str = re.sub(r'\\d', '', bbb.split('/')[0]) + ' '\n",
    "for meiten in bbb.split('/'):\n",
    "    ret_str += meiten[-2:] + '/'\n",
    "ret_str[0:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import pandas as pd\n",
    "import function as func\n",
    "\n",
    "\n",
    "df_all = pd.read_csv('data_base_all.csv', encoding='utf-8').fillna('')\n",
    "df_target = func.processing_data_frame(df_all)\n",
    "df_target.iloc[0].URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.randint(0, 9, 5)\n",
    "b = np.random.randint(0, 9, 5)\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.dot(a, b))\n",
    "\n",
    "a = np.random.randint(0, 9, (3, 2))\n",
    "b = np.random.randint(0, 9, (2, 3))\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def func(row):\n",
    "    return row['a'] + row['b']\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "df['c'] = df['a'].apply(lambda x: x * 2)\n",
    "df['d'] = df.apply(func, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_sample = np.random.normal(size=1000000)\n",
    "\n",
    "def non_vectorize(array_sample):\n",
    "    result = []\n",
    "    for i in array_sample:\n",
    "        result.append(i*i)\n",
    "    return np.array(result)\n",
    "\n",
    "%time non_vectorize_result = non_vectorize(array_sample)\n",
    "\n",
    "def vectorize(array_sample):\n",
    "    return array_sample*array_sample\n",
    "\n",
    "%time vectorize_result = vectorize(array_sample)\n",
    "\n",
    "print(non_vectorize(array_sample))\n",
    "print(vectorize(array_sample))\n",
    "\n",
    "aaa = [1, 2, 3, 4, 5]\n",
    "non_vectorize(aaa)\n",
    "\n",
    "%time _ = [i*i for i in array_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "YOSAN_LIST = {\n",
    "    '-': 0, '～￥999': 1, '￥1000～￥1999': 2, '￥2000～￥2999': 3, '￥3000～￥3999': 4, '￥4000～￥4999': 5, '￥5000～￥5999': 6, '￥6000～￥7999': 7, '￥8000～￥9999': 8, \n",
    "    '￥10000～￥14999': 9, '￥15000～￥19999': 10, '￥20000～￥29999': 11, '￥30000～￥39999': 12, '￥40000～￥49999': 13, '￥50000～￥59999': 14, '￥60000～￥79999': 15, '￥80000～￥99999': 15, '￥100000～': 16, \n",
    "}\n",
    "\n",
    "df_all = pd.read_csv('data_base.csv', encoding='utf-8', low_memory=False).fillna('')\n",
    "df_all['予算'] = df_all['予算(夜)'].apply(lambda x: YOSAN_LIST[x])\n",
    "df_all[df_all.予算 == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL\n",
       "https://tabelog.com/hokkaido/A0101/A010101/23007801/      きりたんぽ\n",
       "https://tabelog.com/hokkaido/A0101/A010101/23012960/       ほうとう\n",
       "https://tabelog.com/hokkaido/A0101/A010101/27109896/     立ち食い寿司\n",
       "https://tabelog.com/hokkaido/A0101/A010101/27123935/      シュラスコ\n",
       "https://tabelog.com/hokkaido/A0101/A010101/32002971/       どじょう\n",
       "                                                         ...   \n",
       "https://tabelog.com/hokkaido/A0101/A010101/47028135/    和食(その他)\n",
       "https://tabelog.com/hokkaido/A0101/A010101/47028138/        居酒屋\n",
       "https://tabelog.com/hokkaido/A0101/A010101/47028159/      定食・食堂\n",
       "https://tabelog.com/hokkaido/A0101/A010101/47028178/        NaN\n",
       "https://tabelog.com/hokkaido/A0101/A010101/47028179/       たこ焼き\n",
       "Length: 233, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_base_all.csv', index_col='URL', encoding='utf-8', low_memory=False)\n",
    "\n",
    "# df1 = pd.DataFrame({'ジャンル': [1, 2, 3]})\n",
    "# df2 = pd.DataFrame({'ジャンル': [3, 4, 5]})\n",
    "df2 = pd.concat([df.ジャンル1, df.ジャンル2, df.ジャンル3])\n",
    "df3 = df2[~df2.duplicated(keep='last')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['きりたんぽ',\n",
       " 'ほうとう',\n",
       " '立ち食い寿司',\n",
       " 'シュラスコ',\n",
       " 'どじょう',\n",
       " 'トルコ料理',\n",
       " '牛カツ',\n",
       " '小籠包',\n",
       " 'タイスキ',\n",
       " '屋形船・クルージング',\n",
       " 'ロシア料理',\n",
       " 'アフリカ料理',\n",
       " '立ち食いそば',\n",
       " 'スリランカ料理',\n",
       " '広東料理',\n",
       " 'インドネシア料理',\n",
       " 'あなご',\n",
       " '社員食堂',\n",
       " 'くじら料理',\n",
       " '中華菓子',\n",
       " 'モダンスパニッシュ',\n",
       " '上海料理',\n",
       " 'カリフォルニア料理',\n",
       " 'サムギョプサル',\n",
       " 'あんこう',\n",
       " 'ドイツ料理',\n",
       " 'にんにく料理',\n",
       " 'ファミレス',\n",
       " 'オイスターバー',\n",
       " 'マカロン',\n",
       " 'うどんすき',\n",
       " '回転寿司',\n",
       " 'どら焼き',\n",
       " '中国鍋・火鍋',\n",
       " '精進料理',\n",
       " '釜飯',\n",
       " 'オセアニア料理',\n",
       " '京料理',\n",
       " 'ふぐ',\n",
       " '西アジア料理(その他)',\n",
       " '牛タン',\n",
       " '焼きとん',\n",
       " '明石焼き',\n",
       " '旅館・オーベルジュ(その他)',\n",
       " '中華粥',\n",
       " 'うなぎ',\n",
       " 'ちゃんこ鍋',\n",
       " '豚丼',\n",
       " 'すっぽん',\n",
       " '豆腐料理・湯葉料理',\n",
       " '水炊き',\n",
       " '麦とろ',\n",
       " 'ハヤシライス',\n",
       " 'スペイン料理',\n",
       " 'ちゃんぽん',\n",
       " '串焼き',\n",
       " 'もつ料理',\n",
       " 'イノベーティブ・フュージョン',\n",
       " 'オーベルジュ',\n",
       " '西洋各国料理(その他)',\n",
       " 'ビアホール・ビアレストラン',\n",
       " 'たい焼き・大判焼き',\n",
       " 'うどん',\n",
       " 'かに',\n",
       " 'パキスタン料理',\n",
       " '学生食堂',\n",
       " 'おばんざい',\n",
       " 'レストラン(その他)',\n",
       " 'その他',\n",
       " '冷麺',\n",
       " 'お好み焼き・たこ焼き(その他)',\n",
       " 'かつ丼・かつ重',\n",
       " 'ブラジル料理',\n",
       " '馬刺し',\n",
       " '旅館',\n",
       " 'すき焼き',\n",
       " 'モダンフレンチ',\n",
       " 'パブ',\n",
       " '日本茶専門店',\n",
       " 'チョコレート',\n",
       " 'カレーうどん',\n",
       " 'オムライス',\n",
       " 'インド料理',\n",
       " 'タイカレー',\n",
       " '牛丼',\n",
       " 'せんべい',\n",
       " 'もつ焼き',\n",
       " '台湾料理',\n",
       " '中華麺(その他)',\n",
       " '懐石・会席料理',\n",
       " 'スープカレー',\n",
       " '焼きそば',\n",
       " 'シチュー',\n",
       " 'ビアバー',\n",
       " '欧風カレー',\n",
       " '薬膳',\n",
       " '東南アジア料理(その他)',\n",
       " 'つけ麺',\n",
       " 'タイ料理',\n",
       " 'パン',\n",
       " '豚料理',\n",
       " '飲茶・点心',\n",
       " '割烹・小料理',\n",
       " 'バイキング',\n",
       " 'シーフード',\n",
       " 'お好み焼き',\n",
       " '肉まん・中華まん',\n",
       " 'ラウンジ',\n",
       " '馬肉料理',\n",
       " 'もつ鍋',\n",
       " '中国茶専門店',\n",
       " 'ベトナム料理',\n",
       " '親子丼',\n",
       " 'ドーナツ',\n",
       " 'とんかつ',\n",
       " 'フレンチトースト',\n",
       " 'おにぎり',\n",
       " 'ソフトクリーム',\n",
       " '手羽先',\n",
       " 'ホルモン',\n",
       " 'ネパール料理',\n",
       " '韓国料理',\n",
       " 'デリカテッセン',\n",
       " '自然食',\n",
       " 'おでん',\n",
       " 'コーヒー専門店',\n",
       " 'ビアガーデン',\n",
       " '南アジア料理(その他)',\n",
       " '韓国鍋',\n",
       " 'パン・サンドイッチ(その他)',\n",
       " '焼酎バー',\n",
       " 'ハワイ料理',\n",
       " 'ろばた焼き',\n",
       " '大福',\n",
       " 'シンガポール料理',\n",
       " '台湾まぜそば',\n",
       " 'スープ',\n",
       " 'ベーグル',\n",
       " 'インドカレー',\n",
       " 'アメリカ料理',\n",
       " 'もんじゃ焼き',\n",
       " 'ジンギスカン',\n",
       " 'アサイーボウル',\n",
       " '四川料理',\n",
       " 'しゃぶしゃぶ',\n",
       " '地中海料理',\n",
       " 'バームクーヘン',\n",
       " 'そば',\n",
       " 'ジュースバー',\n",
       " '天ぷら・揚げ物(その他)',\n",
       " 'ワインバー',\n",
       " 'タピオカ',\n",
       " '汁なし担々麺',\n",
       " '炭火焼き',\n",
       " '和菓子',\n",
       " '鳥料理',\n",
       " 'スポーツバー',\n",
       " 'パンケーキ',\n",
       " '串揚げ・串かつ',\n",
       " 'そば・うどん・麺類(その他)',\n",
       " '沖縄そば',\n",
       " 'パフェ',\n",
       " '天丼・天重',\n",
       " '担々麺',\n",
       " 'クレープ',\n",
       " 'ピザ',\n",
       " 'ハンバーガー',\n",
       " '寿司',\n",
       " '丼もの(その他)',\n",
       " '野菜料理',\n",
       " 'フルーツパーラー',\n",
       " '餃子',\n",
       " 'かき氷',\n",
       " 'その他肉料理',\n",
       " 'バー',\n",
       " '洋食',\n",
       " '喫茶店',\n",
       " 'コロッケ・フライ',\n",
       " 'イタリアン',\n",
       " '洋食・欧風料理(その他)',\n",
       " '焼肉',\n",
       " '海鮮丼',\n",
       " 'ビストロ',\n",
       " '洋菓子(その他)',\n",
       " 'ステーキ',\n",
       " 'バーベキュー',\n",
       " '肉バル',\n",
       " 'アジア・エスニック料理(その他)',\n",
       " 'サンドイッチ',\n",
       " '油そば',\n",
       " '無国籍料理',\n",
       " '刀削麺',\n",
       " 'バー・お酒(その他)',\n",
       " '立ち飲み居酒屋・バー',\n",
       " 'ハンバーグ',\n",
       " 'からあげ',\n",
       " 'ケーキ',\n",
       " '魚介料理・海鮮料理',\n",
       " 'バル・バール',\n",
       " 'ダイニングバー',\n",
       " '天ぷら',\n",
       " '紅茶専門店',\n",
       " '北京料理',\n",
       " 'アイスクリーム',\n",
       " '郷土料理(その他)',\n",
       " '中華料理',\n",
       " 'フレンチ',\n",
       " '豚しゃぶ',\n",
       " 'ちりとり鍋・てっちゃん鍋',\n",
       " '牛料理',\n",
       " '鉄板焼き',\n",
       " 'カレーライス',\n",
       " 'スイーツ(その他)',\n",
       " '弁当',\n",
       " 'ラーメン',\n",
       " 'カレー(その他)',\n",
       " '鍋(その他)',\n",
       " '日本酒バー',\n",
       " '甘味処',\n",
       " 'メキシコ料理',\n",
       " '中南米料理(その他)',\n",
       " 'カフェ・喫茶(その他)',\n",
       " '沖縄料理',\n",
       " 'パスタ',\n",
       " '焼鳥',\n",
       " '居酒屋・ダイニングバー(その他)',\n",
       " '創作料理',\n",
       " 'カフェ',\n",
       " '和食(その他)',\n",
       " '居酒屋',\n",
       " '定食・食堂',\n",
       " nan,\n",
       " 'たこ焼き']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2[~df2.duplicated(keep='last')]\n",
    "df3.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
